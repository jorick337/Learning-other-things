# ССЫЛКА НА ИСТОЧНИК: https://qudata.com/ml/ru/NN_Base_Torch.html

#region ИМПОРТ

import torch
import numpy as np

# Torch и Numpy похожи, просто torch более удобная библиотека для работы с нейросетями

e  = torch.eye(2)       # единичная матрица 2x2 c 1 по главной диагонали
#print(e)               # tensor([[1. 0.][0. 1.]])

#endregion

#region СОЗДАНИЕ ТЕНЗОРОВ

# Функционал схожий с Numpy
v = torch.empty(10)         # вектор из 10 элементов float32 (мусор)
#print(v)                    
m = torch.empty(2, 3)       # матрица формы (2,3)    float32 (мусор)
#print(m)
x = torch.empty_like(m)     # с мусором, такой же формы как m
#print(x)

# tensor - создает тензор по списку Python или массиву Numpy
# При выводе через print всегда пишет tenzor(матрица, тип данных значенений)
# Тип пишется только если отличается от стандартного
x = torch.tensor( [ [0,1,2], [3,4,6] ] ) # матрица формы  (2,3) int64 из списка
#print( x )  # tenzor([ [0 1 2] [3 4 6] ])                        
s = torch.tensor(137.)                   # скаляр (dim=0) типа  float32 (точка!)
#print( s )  # tenzor(137.)
# Тип float хотя и без точки
s = torch.tensor(137, dtype=torch.double)
#print(s)  # tenzor(137., dtype=torch.double)
        
#print(np.eye(3))      # Выведет матрицу (3,3) где главная диагональ равна 1.
# from_numpy - перевод из numpy тензора в тензор torch                   
e = torch.from_numpy( np.eye(3) )        # из numpy-тензора (с его памятью)
#print(e)   # выведет tenzor(np.eye(3), float64)

# Сравнение тензора torch и numpy
# numpy - переводит в формат Numpy тензоры torch
#print( x )                               # tensor([[0., 1., 2.], [3., 4., 6.]])
#print( x.numpy() )                       # numpy-тензор (в той же памяти)

# endregion

#region ОСНОВНЫЕ СВОЙСТВА ТЕНЗОРА

x = torch.tensor( [ [0,1,2], [3,4,6] ] )

# dim - размерность, type - тип элементов, numel - их количество
#print( x.dim(),  x.type(), x.numel() )   # 2 torch.LongTenzor (int64) 6

# size - метод, возвращающий размер тензора
# shape - атрибут тензора, возврашаюшего размер тензора
# (size == shape)
#print( x.size(), x.shape )      # ([2, 3])   

# tuple() - преобразует объект типа torch.size в кортеж Python, 
# * - штука Python, которая распаковывает все значения отдельно друг от друга 
#print( tuple(x.shape), *x.shape )           # (2, 3) и 2 3 

s = torch.tensor(137, dtype=torch.double)
# item - покажет элемент
# dim = 0 т.к. скалярные тензоры(с одним числом) в torch интерпретируются с 0 размером
#print( s.item(), s.dim()  )   # 137 0              

#endregion

#region ТИПЫ ТЕНЗОРОВ

# Tensor - выделяет память но не инициализирует значения
x = torch.Tensor(2,3)                    # матрица (2,3) из 6 элементов float32 (мусор)
#print(x)

# Копирование тензоров с определенным типом
# long - переводит в int64 новый тензор
# если слишком большое число то ставит самое высокое из рамок 
# типа int64(от -9223372036854775808 до 9223372036854775807)
# если близкое к нулю или другому числу то приводит к целому
y = x.long()
#print(y) # случайные значения из памяти, переведенные в int64

# float = float32, double = float64 - разница в количестве нулей после запятой
y = x.float()                            # float32 новый тензор
#print(y)
y = x.double()                           # float64 новый тензор
#print(y)

#endregion

#region ИНИЦИАЛИЗАЦИЯ

# empty - мусорные значения, zeros - матрица с нулями
# element_size - выводит размер в байтах для каждого элемента
x = torch.empty(2,3, dtype=torch.float32)   # float32 - меньше значений
#print(x.element_size())                     # 4
x = torch.empty(2,3, dtype=torch.double)    # float64 - больше значений
#print(x.element_size())                     # 8
y = torch.zeros(2,3, dtype=torch.int32)     # int32 - меньше значений
#print(y.element_size())                     # 4
y = torch.zeros(2,3, dtype=torch.long)      # int64 - больше значений
#print(y.element_size())                     # 8

# По умолчанию идет тип данных float32
y = torch.zeros (2, 3)                   
# zeros_like - копирует форму другого тензора с 0
x = torch.zeros_like(y)                  
#print(y,x)

# ones - заполняет матрицу единицами по форме,
# ones_like - копирует форму другого тензора с 1
x = torch.ones (2, 3)                    
x = torch.ones_like(y)                   
#print(x)

# full - заполняет матрицу конкректными значениями
x = torch.full((2, 3), 3.14159265)       # заполнить матрицу 2x3 числом pi 
#print(x)

# eye - создает матрицу с 1 на главной диагонали
x = torch.eye(3)       # [ [1., 0., 0.] [0., 1., 0.] [0. 0. 1.] ]
#print(x)
x = torch.eye(2,3)     # [ [1., 0., 0.] [0., 1., 0.] ]
#print(x)

# linkspase - как в Numpy равномерно распределяет значения 
x = torch.linspace(0,2,5)  #[0.0,0.5,1.0,1.5,2.0] - от 0 до 2, чтобы их было 5
#print(x)

# rand - создает матрицу со значениями случайными от 0 до 1
x = torch.rand (2, 3)                    
#print(x)
# randn - создает матрицу со значениями нормального распределения(гаусс)
x = torch.randn(2, 3)                    # 2x3 нормально  случ.матрица (mean=0, var=1)
#print(x) 

# uniform_ - меняет значения у тензора на выбранный диапозон
x = torch.empty(3).uniform_(0, 1)        # вектор с равномерным распределением [0..1]
#print(x)
# normal - такое же нормальное распределение(гауса), как и ранее в randn
x = torch.empty(3).normal_(mean=0,std=1) # вектор с нормальным распределением 
#print(x)

# Возвращают тип int64(8 бит)
# arange(min, max, step) - задает значения в диапозоне с возможностью шага иначе +1
x = torch.arange(4)                      # [0,1,2,3]
x = torch.arange(2,14,3)                 # [2,5,8,11]
 
# randperm - случайно переставляет значения тензора
x = torch.randperm(10)                   
#print(x)
# randint - создает тензор в диапозоне от min до max, выбирая случайные значения
x = torch.randint (1, 10, (2,3))         
#print(x)

#endregion

#region УПРАВЛЕНИЕ ПАМЯТЬЮ

# Функции с _ - передают ссылки, а их собратья без них - нет

x = torch.ones(1)                        # [1.]

# exp - не передает ссылку на объект, они имеют разную память
y = x.exp()                              
#print(x);       # tensor([1.])
y[0]=2;         # меняем значение у первого
#print(x.item()) # 1.0 - оно не меняется, ссылки между ними нет

# exp_ - передает ссылку, имеют одну память
y = x.exp_()
#print(x)               # tensor([2.7183])
y[0]=2;                 # Меняем значение
#print(x.item())        # 2.0

# Другие примеры:
# fill_ и zero_ - также передают ссылки
x = torch.empty(2, 3).fill_(-1)          # матрица из -1
x.zero_()                                # теперь 0 в той же памяти

# Ссылочные переменные - один и тот же объект в памяти
# не создает новый объект, а создает ссылку на него
y = x
#print(y)        # забит 0
# clone - копирование объекта без ссылки
y = x.clone()   
x[0][1] = 52
#print(x) # c 52
#print(y) # без 52

# copy_ - копирует в себя, то есть в свою уже выделенную память, но без ссылки
y.copy_(x)
x[0][2] = 228                               
#print(y)
# Копирование значений когда вероятно они не похожи по форме, без ссылки
y = torch.empty_like(x).copy_(x)         # выделяем память и копируем 
#print(y)

#endregion

#region ОПЕРАЦИИ

# Операции у Torch и Numpy схожие(очень)

x1 = torch.ones(2,3)    # [ [1. 1. 1.] [1. 1. 1.] ]
x2 = torch.ones(2,3)    # [ [1. 1. 1.] [1. 1. 1.] ]

x1[0]   = 2           # [ [1. 1. 1.] [1. 1. 1.] ] => [ [2. 2. 2.] [1. 1. 1.] ] 
x2[:,1] = 3           # [ [1. 1. 1.] [1. 1. 1.] ] => [ [1. 3. 1.] [1. 3. 1.] ]

# [ [2. 2. 2.] [1. 1. 1.] ] + [ [1. 3. 1.] [1. 3. 1.] ] = [ [3. 5. 3.] [2. 4. 2.] ]
y = x1 + x2           
#print(y)        #[ [3., 5., 3.],  [2., 4., 2.]]

# [ [2. 2. 2.] [1. 1. 1.] ] + [ [3., 5., 3.],  [2., 4., 2.]] = [ [5. 7. 5.] [3. 5. 3.] ]
x1 += y
#print(x1) # [ [5. 7. 5.] [3. 5. 3.]

# add_ - добавление значений из другого тензора, не создавая новый тензор x1
# [ [3., 5., 3.],  [2., 4., 2.]] + [ [5. 7. 5.] [3. 5. 3.] = [ [8. 12. 8.] [5. 9. 5.] ]
x1.add_(y)
#print(x1) # [ [8. 12. 8.] [5. 9. 5.] ]

# add_ с alpha=2.0 - y в таком случаем умножается на 2 при этом не изменясь
# y = [ [3., 5., 3.],  [2., 4., 2.]] *2 = [ [6., 10., 6.],  [4., 8., 4.]]
# [ [8. 12. 8.] [5. 9. 5.] ] + [ [6., 10., 6.],  [4., 8., 4.]] = 
# [ [14. 22. 14.] [9. 17. 9.] ]
x1.add_(y, alpha=2.0)  # x += 2*y (так быстрее для больших тензоров)
#print(x1)   # [ [14. 22. 14.] [9. 17. 9.] ]

# [ [14. 22. 14.] [9. 17. 9.] ] * [ [3., 5., 3.],  [2., 4., 2.]] = 
# [ [42. 110. 42.] [18. 68. 18.] ]
x1 *= y
#print(x1)

# mul_ - выполняет умножение без создания нового тензора в памяти
# [ [42. 110. 42.] [18. 68. 18.] ] * [ [3., 5., 3.],  [2., 4., 2.]] =
# [ [126. 550. 126.] [36. 272. 36.] ]
x1.mul_(y)
#print(x1)

# random_ и ByteTensor выведет случайные байты(от 0 до 255)
a = torch.ByteTensor(2,3).random_() 
#print(a)

#print(a > 128)         # выдаст список с true false для каждого элемента
# uint8 - тип данных, хранящий числа от 0 до 255
#print(a[a > 128])      # выдаст элементы больше 128

# Перемешивание тензоров без ссылки друг на друга
X = torch.arange(10)                # [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Y = -X                              # [ 0,-1,-2,-3,-4,-5,-6,-7,-8,-9]
#print(X,Y) # Y не поменял X, но если сделалали бы Y=X, то поменял бы

# randperm создаст тензор со случайными значениями по длине X
idx = torch.randperm(X.shape[0]) 
#print(X.shape[0])   # 10
#print(idx)          # случайные значения в диапозоне 10
#print(X)            # [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
# Индексы X будут перемешаны в соответствии с idx, например:
# Строка с индексом idx[0] = _ будет первой
# Строка с индексом idx[1] = _ будет второй и т.д.
X = X[idx]          # в случайном порядке
#print(X)
Y = Y[idx]          # [-4,-9,-7,-3,-2, 0,-5,-6,-1,-8]
#print(Y)

#endregion

#region



#endregion

#region



#endregion