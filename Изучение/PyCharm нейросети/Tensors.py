# ССЫЛКА НА ИСТОЧНИК: https://qudata.com/ml/ru/NN_Base_Torch.html

#region ИМПОРТ

import torch
import numpy as np

# Torch и Numpy похожи, просто torch более удобная библиотека для работы с нейросетями

e  = torch.eye(2)       # единичная матрица 2x2 c 1 по главной диагонали
#print(e)               # tensor([[1. 0.][0. 1.]])

#endregion

#region СОЗДАНИЕ ТЕНЗОРОВ

# Функционал схожий с Numpy
v = torch.empty(10)         # вектор из 10 элементов float32 (мусор)
#print(v)                    
m = torch.empty(2, 3)       # матрица формы (2,3)    float32 (мусор)
#print(m)
x = torch.empty_like(m)     # с мусором, такой же формы как m
#print(x)

# tensor - создает тензор по списку Python или массиву Numpy
# При выводе через print всегда пишет tenzor(матрица, тип данных значенений)
# Тип пишется только если отличается от стандартного
x = torch.tensor( [ [0,1,2], [3,4,6] ] ) # матрица формы  (2,3) int64 из списка
#print( x )  # tenzor([ [0 1 2] [3 4 6] ])                        
s = torch.tensor(137.)                   # скаляр (dim=0) типа  float32 (точка!)
#print( s )  # tenzor(137.)
# Тип float хотя и без точки
s = torch.tensor(137, dtype=torch.double)
#print(s)  # tenzor(137., dtype=torch.double)
        
#print(np.eye(3))      # Выведет матрицу (3,3) где главная диагональ равна 1.
# from_numpy - перевод из numpy тензора в тензор torch                   
e = torch.from_numpy( np.eye(3) )        # из numpy-тензора (с его памятью)
#print(e)   # выведет tenzor(np.eye(3), float64)

# Сравнение тензора torch и numpy
# numpy - переводит в формат Numpy тензоры torch
#print( x )                               # tensor([[0., 1., 2.], [3., 4., 6.]])
#print( x.numpy() )                       # numpy-тензор (в той же памяти)

# endregion

#region ОСНОВНЫЕ СВОЙСТВА ТЕНЗОРА

x = torch.tensor( [ [0,1,2], [3,4,6] ] )

# dim - размерность, type - тип элементов, numel - их количество
#print( x.dim(),  x.type(), x.numel() )   # 2 torch.LongTenzor (int64) 6

# size - метод, возвращающий размер тензора
# shape - атрибут тензора, возврашаюшего размер тензора
# (size == shape)
#print( x.size(), x.shape )      # ([2, 3])   

# tuple() - преобразует объект типа torch.size в кортеж Python, 
# * - штука Python, которая распаковывает все значения отдельно друг от друга 
#print( tuple(x.shape), *x.shape )           # (2, 3) и 2 3 

s = torch.tensor(137, dtype=torch.double)
# item - покажет элемент
# dim = 0 т.к. скалярные тензоры(с одним числом) в torch интерпретируются с 0 размером
#print( s.item(), s.dim()  )   # 137 0              

#endregion

#region ТИПЫ ТЕНЗОРОВ

# Tensor - выделяет память но не инициализирует значения
x = torch.Tensor(2,3)                    # матрица (2,3) из 6 элементов float32 (мусор)
#print(x)

# Копирование тензоров с определенным типом
# long - переводит в int64 новый тензор
# если слишком большое число то ставит самое высокое из рамок 
# типа int64(от -9223372036854775808 до 9223372036854775807)
# если близкое к нулю или другому числу то приводит к целому
y = x.long()
#print(y) # случайные значения из памяти, переведенные в int64

# float = float32, double = float64 - разница в количестве нулей после запятой
y = x.float()                            # float32 новый тензор
#print(y)
y = x.double()                           # float64 новый тензор
#print(y)

#endregion

#region ИНИЦИАЛИЗАЦИЯ

# empty - мусорные значения, zeros - матрица с нулями
# element_size - выводит размер в байтах для каждого элемента
x = torch.empty(2,3, dtype=torch.float32)   # float32 - меньше значений
#print(x.element_size())                     # 4
x = torch.empty(2,3, dtype=torch.double)    # float64 - больше значений
#print(x.element_size())                     # 8
y = torch.zeros(2,3, dtype=torch.int32)     # int32 - меньше значений
#print(y.element_size())                     # 4
y = torch.zeros(2,3, dtype=torch.long)      # int64 - больше значений
#print(y.element_size())                     # 8

# По умолчанию идет тип данных float32
y = torch.zeros (2, 3)                   
# zeros_like - копирует форму другого тензора с 0
x = torch.zeros_like(y)                  
#print(y,x)

# ones - заполняет матрицу единицами по форме,
# ones_like - копирует форму другого тензора с 1
x = torch.ones (2, 3)                    
x = torch.ones_like(y)                   
#print(x)

# full - заполняет матрицу конкректными значениями
x = torch.full((2, 3), 3.14159265)       # заполнить матрицу 2x3 числом pi 
#print(x)

# eye - создает матрицу с 1 на главной диагонали
x = torch.eye(3)       # [ [1., 0., 0.] [0., 1., 0.] [0. 0. 1.] ]
#print(x)
x = torch.eye(2,3)     # [ [1., 0., 0.] [0., 1., 0.] ]
#print(x)

# linkspase - как в Numpy равномерно распределяет значения 
x = torch.linspace(0,2,5)  #[0.0,0.5,1.0,1.5,2.0] - от 0 до 2, чтобы их было 5
#print(x)

# rand - создает матрицу со значениями случайными от 0 до 1
x = torch.rand (2, 3)                    
#print(x)
# randn - создает матрицу со значениями нормального распределения(гаусс)
x = torch.randn(2, 3)                    # 2x3 нормально  случ.матрица (mean=0, var=1)
#print(x) 

# uniform_ - меняет значения у тензора на выбранный диапозон
x = torch.empty(3).uniform_(0, 1)        # вектор с равномерным распределением [0..1]
#print(x)
# normal - такое же нормальное распределение(гауса), как и ранее в randn
x = torch.empty(3).normal_(mean=0,std=1) # вектор с нормальным распределением 
#print(x)

# Возвращают тип int64(8 бит)
# arange(min, max, step) - задает значения в диапозоне с возможностью шага иначе +1
x = torch.arange(4)                      # [0,1,2,3]
x = torch.arange(2,14,3)                 # [2,5,8,11]
 
# randperm - случайно переставляет значения тензора
x = torch.randperm(10)                   
#print(x)
# randint - создает тензор в диапозоне от min до max, выбирая случайные значения
x = torch.randint (1, 10, (2,3))         
#print(x)

#endregion

#region УПРАВЛЕНИЕ ПАМЯТЬЮ

# Функции с _ - передают ссылки, а их собратья без них - нет

x = torch.ones(1)                        # [1.]

# exp - не передает ссылку на объект, они имеют разную память
y = x.exp()                              
#print(x);       # tensor([1.])
y[0]=2;         # меняем значение у первого
#print(x.item()) # 1.0 - оно не меняется, ссылки между ними нет

# exp_ - передает ссылку, имеют одну память
y = x.exp_()
#print(x)               # tensor([2.7183])
y[0]=2;                 # Меняем значение
#print(x.item())        # 2.0

# Другие примеры:
# fill_ и zero_ - также передают ссылки
x = torch.empty(2, 3).fill_(-1)          # матрица из -1
x.zero_()                                # теперь 0 в той же памяти

# Ссылочные переменные - один и тот же объект в памяти
# не создает новый объект, а создает ссылку на него
y = x
#print(y)        # забит 0
# clone - копирование объекта без ссылки
y = x.clone()   
x[0][1] = 52
#print(x) # c 52
#print(y) # без 52

# copy_ - копирует в себя, то есть в свою уже выделенную память, но без ссылки
y.copy_(x)
x[0][2] = 228                               
#print(y)
# Копирование значений когда вероятно они не похожи по форме, без ссылки
y = torch.empty_like(x).copy_(x)         # выделяем память и копируем 
#print(y)

#endregion

#region ОПЕРАЦИИ

# Операции у Torch и Numpy схожие(очень)

x1 = torch.ones(2,3)    # [ [1. 1. 1.] [1. 1. 1.] ]
x2 = torch.ones(2,3)    # [ [1. 1. 1.] [1. 1. 1.] ]

x1[0]   = 2           # [ [1. 1. 1.] [1. 1. 1.] ] => [ [2. 2. 2.] [1. 1. 1.] ] 
x2[:,1] = 3           # [ [1. 1. 1.] [1. 1. 1.] ] => [ [1. 3. 1.] [1. 3. 1.] ]

# [ [2. 2. 2.] [1. 1. 1.] ] + [ [1. 3. 1.] [1. 3. 1.] ] = [ [3. 5. 3.] [2. 4. 2.] ]
y = x1 + x2           
#print(y)        #[ [3., 5., 3.],  [2., 4., 2.]]

# [ [2. 2. 2.] [1. 1. 1.] ] + [ [3., 5., 3.],  [2., 4., 2.]] = [ [5. 7. 5.] [3. 5. 3.] ]
x1 += y
#print(x1) # [ [5. 7. 5.] [3. 5. 3.]

# add_ - добавление значений из другого тензора, не создавая новый тензор x1
# [ [3., 5., 3.],  [2., 4., 2.]] + [ [5. 7. 5.] [3. 5. 3.] = [ [8. 12. 8.] [5. 9. 5.] ]
x1.add_(y)
#print(x1) # [ [8. 12. 8.] [5. 9. 5.] ]

# add_ с alpha=2.0 - y в таком случаем умножается на 2 при этом не изменясь
# y = [ [3., 5., 3.],  [2., 4., 2.]] *2 = [ [6., 10., 6.],  [4., 8., 4.]]
# [ [8. 12. 8.] [5. 9. 5.] ] + [ [6., 10., 6.],  [4., 8., 4.]] = 
# [ [14. 22. 14.] [9. 17. 9.] ]
x1.add_(y, alpha=2.0)  # x += 2*y (так быстрее для больших тензоров)
#print(x1)   # [ [14. 22. 14.] [9. 17. 9.] ]

# [ [14. 22. 14.] [9. 17. 9.] ] * [ [3., 5., 3.],  [2., 4., 2.]] = 
# [ [42. 110. 42.] [18. 68. 18.] ]
x1 *= y
#print(x1)

# mul_ - выполняет умножение без создания нового тензора в памяти
# [ [42. 110. 42.] [18. 68. 18.] ] * [ [3., 5., 3.],  [2., 4., 2.]] =
# [ [126. 550. 126.] [36. 272. 36.] ]
x1.mul_(y)
#print(x1)

# random_ и ByteTensor выведет случайные байты(от 0 до 255)
a = torch.ByteTensor(2,3).random_() 
#print(a)

#print(a > 128)         # выдаст список с true false для каждого элемента
# uint8 - тип данных, хранящий числа от 0 до 255
#print(a[a > 128])      # выдаст элементы больше 128

# Перемешивание тензоров без ссылки друг на друга
X = torch.arange(10)                # [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Y = -X                              # [ 0,-1,-2,-3,-4,-5,-6,-7,-8,-9]
#print(X,Y) # Y не поменял X, но если сделалали бы Y=X, то поменял бы

# randperm создаст тензор со случайными значениями по длине X
idx = torch.randperm(X.shape[0]) 
#print(X.shape[0])   # 10
#print(idx)          # случайные значения в диапозоне 10
#print(X)            # [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
# Индексы X будут перемешаны в соответствии с idx, например:
# Строка с индексом idx[0] = _ будет первой
# Строка с индексом idx[1] = _ будет второй и т.д.
X = X[idx]          # в случайном порядке
#print(X)
Y = Y[idx]          # [-4,-9,-7,-3,-2, 0,-5,-6,-1,-8]
#print(Y)

# Объединение тензоров по осям
x1 = torch.zeros(2,3)             # [ [0 0 0] [0 0 0] ]
x2 = torch.ones(2,3)              # [ [1 1 1] [1 1 1] ]

# cat - объединяет по оси(dim)
# [ [0 0 0] [0 0 0] ] и [ [1 1 1] [1 1 1] ] по dim = 0:
#print(torch.cat([x1, x2], dim=0))           # [ [0 0 0] [ 0 0 0] [1 1 1] [1 1 1] ]
# [ [0 0 0] [0 0 0] ] и [ [1 1 1] [1 1 1] ] по dim = 1:
#print(torch.cat([x1, x2], dim=1))           # [ [0 0 0 1 1 1] [0 0 0] [1 1 1] ]

# stack - объединяет вдоль НОВОЙ оси, а не существующей
# [ [0 0 0] [0 0 0] ] и [ [1 1 1] [1 1 1] ]
#print(torch.stack([x1, x2]))               # [ [ [0 0 0] [0 0 0] [1 1 1] [1 1 1] ] ]

#endregion

#region ТЕНЗОРНЫЕ СВЕРТКИ

u = torch.arange(5)     # [0 1 2 3 4]
v = torch.arange(5,10)  # [5 6 7 8 9]
x = torch.tensor([ [10, 11, 12, 13, 14] ])      # (1,5) 
y = torch.tensor([ [1], [2], [3], [4], [5] ])   # (5,1)

# dot - скалярно умножает одномерные векторы
# [0 1 2 3 4] * [5 6 7 8 9] = 0*5 + 1*6 + 2*7 + 3*8 + 4*9 = 20 + 24 + 36 = 80
#print(v.dot(u))

# mv - умножает двумерный тензор на одномерный
# [ [10, 11, 12, 13, 14] ] * [5 6 7 8 9] = 10*5+11*6+12*7+13*8+14*9 = 
# 50 + 66 + 84 + 104 + 126 = 200 + 230 = 430
#print(x.mv(v)) # Правило матриц: (n,s) (s)   = (n)

# mm - умножает только двумерные тензоры
# [ [10, 11, 12, 13, 14] ] * [ [1], [2], [3], [4], [5] ] = 10*1 + 11*2 + 12*3 + 13*4 + 14*5 =
# 32 + 36 + 52 + 70 = 190
#print(x.mm(y)) # Правило матриц: (n,s) (s,m) = (n,m)

x = torch.tensor([ [ [10, 11, 12, 13, 14] ] ])      # (1,1,5)
y = torch.tensor([ [ [1], [2], [3], [4], [5] ] ])   # (5,1,1)

# bmm - умножение для 3D тензоров
# [ [ [10, 11, 12, 13, 14] ] ] * [ [ [1], [2], [3], [4], [5] ] ] = 190
#print(x.bmm(y))               # Правило матриц: (b, n,s) (b, s,m) =   (b, n,m)
# matmul - аналог умножения тензоров из Numpy:
#print(x.matmul(y))             # Правило матриц: (j,1, n,s) (k, s,m) = (j,k, n,m)

t = torch.tensor([0, 1, 2])
m = torch.tensor([ [0], [1], [2] ])
v = torch.tensor([1])

# addmv - вычисляет матричное произведение m*v, где:
# t - одномерный массив с размерность (n,)
# m - двумерный массив с размерность (n, k)
# v - одномерный массив с размерность (k,)
# m  @ v = [ [0], [1], [2] ] @ [1] = = (3,1)+(1,1) = (3,1)
# 0*1 + 1*1+ 2*1 = [ [0 1 2] ] = (3,1) = (3,) = [0 1 2]
# alpha*(m @ v) = 1 * [0 1 2] = [0 1 2]
# beta*t = 1*[0, 1, 2] = [0, 1, 2]
# alpha*(m  @ v)  + beta*t = [0 1 2] + [0, 1, 2] = [0 2 4]
#print(torch.addmv(t, m, v, beta=1, alpha=1))  #  alpha*(m  @ v)  + beta*t

t = torch.tensor([1])           # (1,)
m1 = torch.tensor([ [1, 2] ])   # (1,2)
m2 = torch.tensor([ [1], [2] ]) # (2,1)
# addmm - матричное умножение с добавлением t (m1 и m2 только двумерные массивы)
# m1 @ m2 = [ [1, 2] ] @ [ [1], [2] ] = 1*1 + 2*2 = [5]
# alpha*(m1 @ m2) = 1 * [5] = [5]
# beta*t = 1* [1] = [1]
# alpha*(m1 @ m2) + beta*t = [5] + [1] = [6]
#print(torch.addmm(t,m1,m2, beta=1, alpha=1))  # alpha*(m1 @ m2) + beta*t

x = torch.Tensor([ [2,1,3], [1,2,1] ])  # (2,3) 

# sum - cумма по колонкам (осям)
# sum(0) => [0] = 2+1 = 3; [1] = 1+2 = 3; [2] = 3+1 = 4
# sum(1) => [0] = 2+1+3 = 6; [1] = 1+2+1 = 4
# sum() => 2+1+3+1+2+1 = 10
#print(x.sum(0))        # [3., 3., 4.]
#print(x.sum(1))        # [6., 4.]
#print(x.sum())          # [10.]

# Похожие:
# mean - cреднее арифметическое
#print(x.mean(1))                # [2., 1.33]
# prod - произведение
#print(x.prod(1))                # [6., 2.]
# argmin - выводит индексы минимальных значений 
#print(x.argmin(1))              # [1, 0]

# topk - выводит наибольшие значения и их индексы (2 тензора)
# topk(кол-во значений, dim - по каким осям)
v,i = x.topk(2, dim=1)  # 2 наибольших значения по строкам
#print(v)                # Наибольшие значения   [ [3. 2.] [2. 1.] ]
#print(i)                # Индексы этих значений [ [2 0] [1 0] ]

#endregion

#region ИЗМЕНЕНИЕ ФОРМЫ ТЕНЗОРА

# view и reshape - меняют размерность и число индексов
#print(torch.arange(6).view(2,3))         # [ [0 1 2] [3 4 5] ]
#print(torch.arange(6).reshape(2,3))      # [ [0 1 2] [3 4 5] ]
# Автоматическое определение размерности
#print(torch.arange(6).view(2,-1))         # [ [0 1 2] [3 4 5] ]
   
# view_as - меняет размерность по другому тензору
a = torch.zeros(2,5)    # [ [0 0 0 0 0] [0 0 0 0 0] ] 
b = torch.zeros(10)     # [0 0 0 0 0 0 0 0 0]
#print(b.view_as(a))     # [ [0 0 0 0 0] [0 0 0 0 0] ]

x = torch.tensor([ [0, 1] ])    # (1,2)
# t или t_ - операция транспонтирования() только для 2D матриц(ссылки сохраняются)
# t - создает новый тензор(в памяти)
# t_ - изменяет новый тензор(в памяти)
# (1,2) => (2,1) = [ [0, 1] ] [ [0] [1] ] => [ [0] [1] ]
z = x.t();  #print(z)        # [ [0] [1] ]
z = x.t_(); #print(z)        # [ [0] [1] ]

x = torch.tensor([ [ [0, 1] ] ])    # (1,1,2)
# transpose - переставляет оси по значениям
# (1,1,2) => (1,2,1) = [ [ [0, 1] ] ] => [ [ [0] [1] ] ]
#print(x.transpose(1,2))

#endregion

#region



#endregion

#region



#endregion