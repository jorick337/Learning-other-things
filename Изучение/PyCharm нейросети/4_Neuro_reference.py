# ССЫЛКА НА ИСТОЧНИК: https://qudata.com/ml/ru/NN_Base_Torch_NN_Ref.html

#region ИНТЕРФЕЙСЫ ДЛЯ СЛОЕВ(ГОТОВЫЕ)

import torch
# Слои могут быть функциями или классами

# Модуль который содержит функции для слоев(много)
import  torch.nn.functional as F 
# Слой как функция:
N, nX, nY = 1, 2, 3                               # число примеров, входов, выходов
X = torch.ones(N,  nX)                            # [ [1 1] ] - примеры
# Пояснение для весов:
# nY - размерность выходного тензора
# nX - размерность входного тензора
W = torch.ones(nY, nX)                            # [ [1 1] [1 1] [1 1] ] - весы
B = torch.ones(nY)                                # [ 1 1 1 ] - смещение

# linear - преобразует тензор X с весами W и смещением B по формуле:
# Y = X*W.t() + B
# W.t() = [ [1 1 1] [1 1 1] ] - транспонированная версия W(нужна для умножения матриц)
# X*W.t() = (1,2)*(2,3) = (1,3) = [ [1 1] ] * [ [1 1 1] [1 1 1] ] = 
# [ 1*1+1*1 1*1+1*1 1*1+1*1] = [2 2 2]
# X*W.t() + B = [ [2 2 2] ] + [ 1 1 1 ] = [ [3 3 3] ]
Y = F.linear(X, W, B); #print(Y)                 # [ [3. 3. 3.] ]
# Аналоги этой функции:
Y = X.mm(W.t())+B; #print(Y)                    # [ [3. 3. 3.] ]
Y = torch.addmm(B,X,W.t()); #print(Y)           # [ [3. 3. 3.] ]

# Слой как класс
import torch.nn as nn

X = torch.ones(N,  nX)  # (1,2)
# Создание слоя без весов и смещения, чисто из размерности
# Где nX - размер входного слоя; nY - размер выходного слоя
fc =  nn.Linear(nX, nY) # (2, 3) - класс слоя
# передача на вход матрицы X (2 размер по 1 оси и 2 размер у fc совпадают)
Y = fc(X)
# При формировании слоя не были указаны веса и смещение из-за чего они 
# определяются сами и в таком случае тензор будет иметь случайные значения
#print(Y)        # tensor([[s s s]],grad_fn=<Addmm>), где s - случайное значение
#print(fc.weight, fc.bias)   # весы и смещение

# Класс слоя объявляется свойство requires_grad=True всем своим параметрам
# Из-за чего строятся градиенты у этих параметров
#print(fc.bias)            # tensor([s s s], requires_grad=True) - смещение
#print(fc.bias.is_leaf)    # True - тензор графа
#print(fc.bias.grad)       # None - нет градиента

# В случае когда Y будет участвовать в какой-нибудь функции и после backward будут
# будут вычислены все графы Y, а в них и есть смещение
# Функция ошибки - определяет насколько сильно предсказание модели(Y) 
# отличается от истинного значения(T - которое вычисляется при backward)
# То есть torch.sum(Y*Y) вычисляет скаляр(одно число) из суммы квадратов Y
# После обратного прохода вычисляется T - истина, т.к. весы и смещения и находят
# значения правильные из входных(основываясь на весах и смещении прогнозируются ошибки)
L = torch.sum(Y*Y)
L.backward()                # вычисление градиентов для fc.bias и fc.weight
#print(fc.weight.grad)       # tensor([s s s]) - градиент весов
#print(fc.bias.grad)         # tensor([s s s]) - градиент смещения

#endregion

#region ПОЛНОСВЯЗНЫЙ СЛОЙ

N, nX, nY = 1, 2, 3  
W = torch.ones(nY, nX)  # весы
B = torch.ones(nY)      # смещение

# nn.Linear(in_features, out_features, bias=True) - преобразует y = x*W.t() + b, где
# W(матрица весов) храниться в транспонированном виде, так чтобы выполнялось x*W
# x - основная матрица, а b - смещение

# В данном случае не заданы весы и смещения, поэтому если это необходимо, то нужно
# присваивать в no_grad оболочке
fc = nn.Linear(nX, nY)      
with torch.no_grad():
    fc.weight.copy_(W)          # устанавливаем матрицу весов
    fc.bias.copy_(B)            # устанавливаем вектор смещений

# Если необходимо не менять весы или смещение(то есть не менять при обучении), то :
# fc.weight.requires_grad = False или fc.bias.requires_grad = False

# Вот как устроена эта же функция в torch.nn.functional:
# она требует тензор, весы и не обязательное смещение при этом весы должны выполнять
# условие матричного умножения
# def linear(X, weight, bias=None):                 # смещение не обязательно
#     if X.dim() == 2 and bias is not None:         # если 2 оси и задано смещение
#         ret = torch.addmm(bias, X, weight.t())    # X@(w.t()) + b
#     else:
#         output = X.matmul(weight.t())
#         if bias is not None: output += bias
#         ret = output
#     return ret

#endregion

#region СЛОЙ ЭМБЕДДИНГА

# nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None,
# norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)

# Обязательными являются num_embeddings(размер массива) и embedding_dim(размерность)
# Принимает тензор с Long переменными

# создаст весы размерность (5,2)
emb = nn.Embedding(5, 2, padding_idx=0)
# X определяет индексы которые нужно выбрать из тензора весов
X = torch.tensor([0,2,1])
 
#print(emb.weight)   # tensor([ [s0 s0] [s1  s1] [s2  s2] [s3 s3] [s4 s4] ],
                    # requires_grad=True)
#print(emb(X))       # tensor([ [s0 s0] [s2  s2] [s1  s1] ],  grad_fn=<EmbeddingBackward0>)

# Параметры:

# paddind_idx - задает индексу постоянное значение нуля
# padding_idx=1 - значит в x[0][2] = [0 0] (т.к. emb.weight[0][2] = [0 0])
emb = nn.Embedding(5, 2, padding_idx=1)
#print(emb(X))       # tensor([ [s0 s0] [s2  s2] [0  0] ],  grad_fn=<EmbeddingBackward0>)
# Где это используется ? :
# Например в разговорных нейросетях:
# "Привет" => токены [2, 3]
# "Как дела" => токены [4, 5, 6] , то x выглядел бы так:
# [ [2 3 0] [4 5 6] ] - то есть там где 0 не будет происходить 
# вычислений, что очень удобно

# max_norm - задает максимальную длину вектора и если превышается, 
# то вектор перенормируется(меняет max_norm на ту длину которая превысила)
# По умолчанию это значение равно 2
# Формула для нахождения: N = math.sqrt(sum), где sum - сумма значений тензора
# Пример:
# emb(X) = [[ 0.5561, -0.1329],[ 0.3771, -0.0645],[ 0.3371, -0.3638]], то
# N[1] = math.sqrt(0.5561-0.1329) = 0.5718 и т.д.
emb = nn.Embedding(5, 2, max_norm=3)
#print(emb(X))   # tensor([ [s0 s0] [s1  s1] [s2  s2] [s3 s3] [s4 s4] ],
                # requires_grad=True)
# norm - выводит тензор с нормализованными значениями от 0 до 3(max_norm=3) для 
# каждого элемента по 1 оси emb(X)   
#print(torch.norm(emb(X),dim=1)) # [s s s], где s - значения нормализации
# Зачем нужна нормировка? :
# В тензоре могут быть 1000 значений скажем от 0 до 1 или от 1 до 1000
# Чтобы было удобнее с ними работать их нормируют в более комфортные значения
# Нормализация помогает привести данные к одинаковому масштабу

# scale_grad_by_freq - регулирует значения для индексов, то есть
# если true: часто встречающиеся индексы будут уменьшаться, а те что реже увеличиваться
# По итогу будет создан баланс между частыми и редкими индексами
weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6], [7, 8.1, 9]])
# from_pretrained - предварительно созданые векторы для быстрого использования:
# from_pretrained(embeddings, freeze=True, padding_idx=None, max_norm=None,
# norm_type=2.0, scale_grad_by_freq=False, sparse=False)
# freeze=False - для обновления весов и градиентов
emb = nn.Embedding.from_pretrained(weight, freeze=False, scale_grad_by_freq=False)
input = torch.LongTensor([0, 1, 1])   # Создать emb по первому индексу weight
output = emb(input)
loss = output.sum()
loss.backward()
# [1 1 1] - [0] индекс встречается 1 раз, [2 2 2] - [1] индекс встречается 2 раза,
# [0 0 0] - [2] индекс встречается 0 раз (тут стоят единицы, т.к. loss очень простая) 
#print(emb.weight.grad)          # [ [1 1 1] [2 2 2] [0 0 0] ]

#endregion

#region СЛОЙ КОНВОЛЮЦИИ

# nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, 
# dilation=1, groups=1, bias=True, padding_mode='zeros') - слой применяется 
# в основном применяется для картинок высотой rows, шириной cols и с in_channels 
# цветовых каналов(тем не менее может применяться не только для изображений)

# На вход входит тензор (N, in_channels, rows,cols)
# На выходе (N, out_channels, rows_out, cols_out)
# По выходному проход фильтры out_channels размерами 
# kernel_size(2,2 - размерность, если kernel_size=2)
# Глубина определяется in_channels

# Параметры:
# padding - задает то на сколько нужно расширить картинку перед прохождением фильтров
# padding_mode - задает то чем будет заполняться эта область
# (zeros, reflect, replicate,circular)
# duration - задает расстояние между пикселями попадающими в фильтр(шаг)

# Пример:
X = torch.zeros(1,1,3,4)    # [ [ [0 0 0 0] [0 0 0 0] [0 0 0 0] ] ]
X[0,0,:,:2] = 1             # [ [ [1 1 0 0] [1 1 0 0] [1 1 0 0] ] ] 
#print(X)   # (1,1,3,4) - одна выборка(1), один канал(1), размер изображения (3,4)

# т.к. kernel_size=2, то фильтры будут размерами (2,2)
# stride по умолчанию (1,1), то есть шаг равен 1 по ширине и высоте
# без смещения
conv = nn.Conv2d(1,1,kernel_size=2,bias=False)
#print(conv)     # Conv2d(1, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)

# Присваивание веса слою вручную(с no_grad, чтобы не считалось сразу, правило такое)
with torch.no_grad():
    conv.weight.copy_(torch.tensor([[-1.,1.], [-1.,1.]]))

# requires_grad=True т.к. это весы у них так всегда по умолчанию(если false, 
# то весы не обновляются, а значит модель не учиться)
#print( conv.weight )    # tensor([[-1.,1.], [-1.,1.]], requires_grad=True)
#print( conv.bias )      # смещение не объявляли
# Расчет выходного тензора(OUTnum - выходной, Hin - входной, K - размер фильтра):
# OUT1 = 1 - поскольку X по первой оси имеет 1, то есть за один прогон одно изображение
# OUT2 = 1 - поскольку у conv значение out_channels равно 1 - количество 
# фильтров(каналов) в слое
# Остальные по формуле: Hnum = (Hin-K[ind])/stride[0])+1
# Hin = (1,1,3,4); K = (2,2); stride = (1,1), то:
# OUT3 = ((Hin[2] - K[0])/1) +1 = ((3-2)/1) +1 = 2
# OUT4 = ((Hin[3] - K[1])/1) +1 = ((4-2)/1) +1 = 3
# Исходный тензор будет иметь размерность (1,1,2,3)
# [ [ [1 1 0 0] [1 1 0 0] [1 1 0 0] ] ]:
# 1 1 0 0
# 1 1 0 0
# 1 1 0 0
# [ [-1 1] [-1 1] ] :
# -1 1
# -1 1
# В таком случае считаем первое скалярное произведение:
# левое верхнее окно
# [ [-1 1] [-1 1] ] @ [ [1 1] [1 1] ] = 1*-1 + 1*1 + 1*-1 + 1*1 = -2+2 = 0 
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [1 0] [1 0] ] = -1*1 + 1*0 + -1*1 + 1*0 = -2
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [0 0] [0 0] ] = -1*0 + 1*0 + -1*0 + 1*0 = 0
# вниз и влево к краю
# [ [-1 1] [-1 1] ] @ [ [1 1] [1 1] ] = 1*-1 + 1*1 + 1*-1 + 1*1 = -2+2 = 0
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [1 0] [1 0] ] = -1*1 + 1*0 + -1*1 + 1*0 = -2
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [0 0] [0 0] ] = -1*0 + 1*0 + -1*0 + 1*0 = 0
# Итого: [ [ [ [0 -2 0] [0 -2 0] ] ] ]
#print( conv(X) )    # tensor([[[[0 -2 0] [0 -2 0]]]], grad_fn=<ConvolutionBackward0>)

#endregion

#region СЛОЙ RNN

# nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='tanh', bias=True,
# batch_first=False, dropout=0, bidirectional=False)
# Предназначен для обработки последовательных данных(текст, временные ряды, 
# аудиофайлы и т.д.)
# Вычисляет новое скрытое состояние по старому и новому(входному)

# Параметры:
# input_size - размерность входа
# hidden_size - размерность выхода
# batch_first - задает индекс батча, что будет использоваться
# num_layers - задает размерность для первой оси скрытого слоя
# dropout - задает вероятность случайного забивания 0 в скрытых состояниях
# формы для того, чтобы избежать переобучения(при 1 вероятно не будеть учиться)
# biddirrectional - если true, то двунаправленная иначе однонаправленная:
# однонапрвленная - сеть генерирует данные по одному направлению к другому
# двунаправленна - сеть генерирует данные от одного к другому и к другому к одному
# (слева направо с права на лево). В таком случае скрытые состояния удваиваются, но
# и сеть становиться более мощной

# Размерность входа(seq_len, batch_size, input_size), 
# где seq_len - число RNN ячеек(входов)

# Слой возвращает все выходы формы(seq_len, batch_size, hidden_size)
# и последнее скрытое состояние формы(num_layers, batch_size, hidden_size)

X_dim  = 2           # размерность входов             = dim(x)
H_dim  = 4           # размерность скрытого состояния = dim(h)
L      = 3           # число входов (ячеек RNN слоя) - сколько векторов на вход
B      = 1           # число примеров (batch_size)

# Создание слоя 2 размерности входов и 4 размерностью скрытого состояния
# Если надо bidirectional=True, то применить к H0 на первой оси 2, а не 1 иначе ошибка
# поскольку при bidirectional=True существет уже два направления по скрытным слоям
rnn = nn.RNN(X_dim, H_dim)

# Входы для слоя:
X  = torch.zeros(L, B, X_dim)   # (3,1,2) [ [ [0 0] ] [ [0 0] ] [ [0 0] ] ]
H0 = torch.zeros(1, B, H_dim)   # (1,1,4) [ [ [0 0 0 0] ] ]

# На выходе: Y - выход; Hn - выход скрытого состояния
# X -> Y = (3,1,2) -> (3,1,4) (взяла 4 с HO, где (1,1,4)), т.к. на каждом 
# из 3 временных шагов(L) будет создано скрытое состояние размерности 4
# Hn = H0 = (1,1,4) = (1,1,4)
# Hn - просто запоминает последнее действие(размерность с которой работал)
Y, Hn = rnn(X, H0)                      # H0 не обязательно, по умолчанию и так 0

#print(tuple(Y.shape), tuple(Hn.shape))  #  (3, 1, 4) (1, 1, 4)
# Последнее значение Y и Hn совпадает, поскольку Hn = последнему присвоенному Y вектору
#print(Y)
#print(Hn)

#endregion

#region СЛОЙ LSTM

# torch.nn.LSTM(input_size, hidden_size, num_layers=1, nonlinearity='tanh', bias=True,
# batch_first=False, dropout=0, bidirectional=False)
# Абсолютный аналог RNN, который использует добавления памяти ячеек
# Ячейка памяти обновляется каждый раз при проходе с учетом текущего входа, 
# предыдущего скрытного состояния и состояния ячейки
# Хоть ячейка и обновляется на каждом временном шаге, тем не менее оно сохраняет 
# долгосрочную информацию для улушения обучения

X_dim  = 10          # размерность входов             = dim(x)
H_dim  = 20          # размерность скрытого состояния = dim(h)
L      = 3           # число входов (ячеек RNN слоя) - сколько векторов на вход
B      = 1           # число примеров (batch_size)

rnn = nn.LSTM(X_dim, H_dim)

X  = torch.zeros(L, B, X_dim)
h0 = torch.zeros(1, B, H_dim)
c0 = torch.zeros(1, B, H_dim)

output, (hn, cn) = rnn(X, (h0, c0))
#print(output)   # тензор с выходами для каждого шага
#print(hn)       # скрытое состояние(такое же как в RNN)
#print(cn)       # тензор состояния ячейки на последнем шаге

# Где используется ? 
# По сравнению с RNN имеет большее влияние по отношению к зависимостям 
# на долгих временных промежутках

#endregion

#region СЛОЙ MULTIHEADATTENTION

# nn.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, 
# add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None)
# Основная задача определить какие части входных данных наиболее важны 
# для текущего элемента

# MultiheadAttention(Q,K,V), где: 
# Q - запрос для которого расчитывается внимание
# K - представление всех элементов последовательности
# V - информация извлекаемая из K
# На вход Q(L,N,E), K и V -> (S,N,E), где: 
# L - длина последовательности на которую обращено внимание(Q - target)
# N - размер батча(количество последовательностей обрабатываемых одновременно)
# E - размерность эмбединга(равная embed_dim) - определяет сколько информации будет 
# кодировано для каждого элемента (длина элементов-значений)
# S - длина последовательности K и V(к которым применино внимание)
# На выход (L,N,E) с весами (N,L,S)

# Весы Q(E,E), K(E,kdim), V(E,vdim), где: 
# kdim, vdim - параметры, что можно задать, но по умолчанию их нет
# (в таком случае равны E)

# Размерность каждой головы равна head_dim = E // num_heads
# На выходе получаются весы равные слою Linear(E,E,bias=bias), если есть bias, то 
# он добавляется для кадого из весов Q,K и V(у каждого свой)

# Если эмбединг входы(размерности тензоров одинаковы), то матрицы упакованы в 
# in_proj_weight формы (3*E, E) иначе это параметры: 
# q_proj_weight, k_proj_weight, v_proj_weight у самого MultiheadAttention
# Смещение(если есть) это in_proj_bias формы(3*E,), а на выход out_proj (там же)
# То есть: nn.MultiheadAttention(E,L).q_proj_weight и т.д.

L = 4  # Длина целевой последовательности(Q)
S = 5  # Длина входной последовательности(K и V)
N = 2  # Размер батча(количество примеров=batch_size)
E = 8  # Размер эмбеддинга(количество на выходе значений=embed_dim)

attention = nn.MultiheadAttention(E,L)

Q = torch.randn(L,N,E)
K = torch.randn(S,N,E)
V = torch.randn(S,N,E)

output, attn_weight = attention(Q,K,V)

# Output = (L,N,E) = (4,2,8)
#print(output)
# Weight = (N,L,S) = (2,4,5):
# N - было столько-то примеров
# L - из такой-то длины значений
# S - которых взяли отсюда
#print(attn_weight)

# Пример реализации многоголового внимания(ключевой компонент в трансформерах 
# типа BERT и GPT), работает только когда L = S -> 5 = 5:
E = 10 # E должна делится на L(то есть embed_dim/num_heads = True)
L = 5

attention = nn.MultiheadAttention(E,L)

Q = torch.randn(L,N,E)
K = torch.randn(S,N,E)
V = torch.randn(S,N,E)

output, attn_weight = attention(Q,K,V)

# Создаются веса для Q,K,V в переменной in_proj_weight:
#print(attention.in_proj_weight)
# Создаются если(bias=True) смещения для Q,K,V в переменной in_proj_bias:
#print(attention.in_proj_bias)

# достанем их для каждого из значений Q,K,V:
q_proj_weight = attention.in_proj_weight[:E,:]
k_proj_weight = attention.in_proj_weight[E:E*2,:]
v_proj_weight = attention.in_proj_weight[E*2:,:]

#endregion

#region СЛОЙ TRANSFORMERENCODERLAYER

# nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048, 
# dropout=0.1, activation='relu')
# Это базовый слой трансформера, используемый в архитектурах трансформеров(это часть 
# более сложной структуры, например, BERT и GPT)

# Параметры:
# embed_dim(d_model) - размерность входных(выходных) эмбедингов(стандарт 512 или 1024)
# то есть на входе должен быть тензор размерность (...,...,512) и т.д.
# Почему такие большие ? 
# Другие люди пробовали разные размерности и выяснили что 512 и 1024 наиболее 
# стабильные и балансные
embed_dim = 512
# num_heads(nhead) - количество голов MULTIHEADATTENTION, то есть модель будет изучать
# сразу несколько взаимосвязей между токинами в последовательности
num_heads = 8
# feedforward_dim - размерность скрытого слоя в полносвязной сети, как работает:
# скажем на вход дали d_model = 512, то поступают векторы именно такой размерности,
# векторы проходят через головы MULTIHEADATTENTION(nhead=8) и результат передается 
# в полносвязную сеть, где размерность равна feedforward_dim = 2048 и уже после 
# активации(работы с этими значениями) она снова преобразуется в вектор размерности 
# d_model = 512, то есть feedforward_dim - это как-бы проходной слой
feedforward_dim = 2048 

encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads,
                                           dim_feedforward=feedforward_dim)

# Пример входных данных: 10 временных шагов, 32 батча, размерность 512
x = torch.rand(1, 2, embed_dim)

output = encoder_layer(x)
# output = (1,2,embed_dim) = (1,2,512)
#print(output)       # два элемента по 512 значений
#print(output.shape)

#endregion

#region СЛОЙ TRANSFORMERENCODER

# nn.TransformerEncoder(encoder_layer, num_layers, norm=None)
# Данный слой состоит из нескольких слоев TRANSFORMERENCODERLAYER, которые состоят из
# слоев MULTIHEADATTENTION и полносвязной сети

E = 512             # размерность эмбединга
num_layers = 6      # число повторяющихся слоев TRANSFORMERENCODERLAYER(будет 
# создано 6 слоев энкодера трансформера, пройдет через них)

# Создание слоя TRANSFORMERENCODERLAYER без dim_feedforward(по умолчанию 2048)
encoder_layer       = nn.TransformerEncoderLayer(d_model=E, nhead=8)
# Создание слоя при помощи другого слоя(сложная сеть получается)
transformer_encoder = nn.TransformerEncoder     (encoder_layer, num_layers=6)

src = torch.rand(1, 2, E)
out = transformer_encoder(src)   
#print(src.shape, out.shape)     # out.shape == src.shape

#endregion

#region ВЫПРЕМЛЕНИЕ ТЕНЗОРА

# nn.Flatten(start_dim=1, end_dim=-1)
# По умолчанию сливает все индексы в один вектор, то есть преобразует 2D и более 
# массивы в одномерные вектора(1,1)

X = torch.ones(1,5,4,3)         
# (2,5,4,3) -> (2, 5*4*3) -> (2,60)
Y = torch.nn.Flatten()(X)       
#print(tuple(Y.shape))                   # (2, 60)

#endregion

#region КОСИНУС МЕЖДУ ВЕКТОРАМИ

# nn.CosineSimilarity(dim=1, eps=1e-08)
# Считает косинус между двумя векторами при этом соблюдая правила:
# Оба входа имеют размерность (*, D, *), где D - должны быть равны у обоих векторов
# Output будет иметь размерность (*,*)
# То есть если будет (*,D,*,*) -> (*,*,*) - D теряется, а D - всегда вторая ось

u, v = torch.randn(100, 3,4, 128), torch.randn(100, 3,4, 128)
output = nn.CosineSimilarity(dim=1, eps=1e-6) (u, v)
#print(output.shape)

#endregion

#region РАССТОЯНИЕ МЕЖДУ ВЕКТОРАМИ

# nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)
# Вычисляет расстояние между векторами, принимая на вход две матрицы (N,D), где 
# D - размерность вектора
# На выходе выдает (N) или (N,1) - если keepdim = True
# Применяется для сравнения пар данных

# Параметры:
# p=2.0 - евклидов расстояние или p=1.0 - манхетонское расстояние - способы 
# нахождения расстояния между точками в пространстве(они разные)
# eps=1e-06 - прибавляется к результату вычисления для того, чтобы улучшить 
# читабельность(чтобы не было цифр с e, как тут)
# keepdim - определяет сохранят ли размерности тензоров после вычисления расстояния
# true - будет иметь ту же размерность что и у входа 
# false - будет иметь уменьшенный результат(ненужное будет убрано)

u, v = torch.randn(10, 5), torch.randn(10, 5)
output = nn.PairwiseDistance(keepdim=False) (u,v)

# При keepdim=True равно (10,1)
# При keepdim=False равно (10,)
print(output.shape)

#endregion

#region



#endregion