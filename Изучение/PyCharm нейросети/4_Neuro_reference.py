# ССЫЛКА НА ИСТОЧНИК: https://qudata.com/ml/ru/NN_Base_Torch_NN_Ref.html

#region ИНТЕРФЕЙСЫ ДЛЯ СЛОЕВ(ГОТОВЫЕ)

import torch
# Слои могут быть функциями или классами

# Модуль который содержит функции для слоев(много)
import  torch.nn.functional as F 
# Слой как функция:
N, nX, nY = 1, 2, 3                               # число примеров, входов, выходов
X = torch.ones(N,  nX)                            # [ [1 1] ] - примеры
# Пояснение для весов:
# nY - размерность выходного тензора
# nX - размерность входного тензора
W = torch.ones(nY, nX)                            # [ [1 1] [1 1] [1 1] ] - весы
B = torch.ones(nY)                                # [ 1 1 1 ] - смещение

# linear - преобразует тензор X с весами W и смещением B по формуле:
# Y = X*W.t() + B
# W.t() = [ [1 1 1] [1 1 1] ] - транспонированная версия W(нужна для умножения матриц)
# X*W.t() = (1,2)*(2,3) = (1,3) = [ [1 1] ] * [ [1 1 1] [1 1 1] ] = 
# [ 1*1+1*1 1*1+1*1 1*1+1*1] = [2 2 2]
# X*W.t() + B = [ [2 2 2] ] + [ 1 1 1 ] = [ [3 3 3] ]
Y = F.linear(X, W, B); #print(Y)                 # [ [3. 3. 3.] ]
# Аналоги этой функции:
Y = X.mm(W.t())+B; #print(Y)                    # [ [3. 3. 3.] ]
Y = torch.addmm(B,X,W.t()); #print(Y)           # [ [3. 3. 3.] ]

# Слой как класс
import torch.nn as nn

X = torch.ones(N,  nX)  # (1,2)
# Создание слоя без весов и смещения, чисто из размерности
# Где nX - размер входного слоя; nY - размер выходного слоя
fc =  nn.Linear(nX, nY) # (2, 3) - класс слоя
# передача на вход матрицы X (2 размер по 1 оси и 2 размер у fc совпадают)
Y = fc(X)
# При формировании слоя не были указаны веса и смещение из-за чего они 
# определяются сами и в таком случае тензор будет иметь случайные значения
#print(Y)        # tensor([[s s s]],grad_fn=<Addmm>), где s - случайное значение
#print(fc.weight, fc.bias)   # весы и смещение

# Класс слоя объявляется свойство requires_grad=True всем своим параметрам
# Из-за чего строятся градиенты у этих параметров
#print(fc.bias)            # tensor([s s s], requires_grad=True) - смещение
#print(fc.bias.is_leaf)    # True - тензор графа
#print(fc.bias.grad)       # None - нет градиента

# В случае когда Y будет участвовать в какой-нибудь функции и после backward будут
# будут вычислены все графы Y, а в них и есть смещение
# Функция ошибки - определяет насколько сильно предсказание модели(Y) 
# отличается от истинного значения(T - которое вычисляется при backward)
# То есть torch.sum(Y*Y) вычисляет скаляр(одно число) из суммы квадратов Y
# После обратного прохода вычисляется T - истина, т.к. весы и смещения и находят
# значения правильные из входных(основываясь на весах и смещении прогнозируются ошибки)
L = torch.sum(Y*Y)
L.backward()                # вычисление градиентов для fc.bias и fc.weight
#print(fc.weight.grad)       # tensor([s s s]) - градиент весов
#print(fc.bias.grad)         # tensor([s s s]) - градиент смещения

#endregion

#region ПОЛНОСВЯЗНЫЙ СЛОЙ

N, nX, nY = 1, 2, 3  
W = torch.ones(nY, nX)  # весы
B = torch.ones(nY)      # смещение

# nn.Linear(in_features, out_features, bias=True) - преобразует y = x*W.t() + b, где
# W(матрица весов) храниться в транспонированном виде, так чтобы выполнялось x*W
# x - основная матрица, а b - смещение

# В данном случае не заданы весы и смещения, поэтому если это необходимо, то нужно
# присваивать в no_grad оболочке
fc = nn.Linear(nX, nY)      
with torch.no_grad():
    fc.weight.copy_(W)          # устанавливаем матрицу весов
    fc.bias.copy_(B)            # устанавливаем вектор смещений

# Если необходимо не менять весы или смещение(то есть не менять при обучении), то :
# fc.weight.requires_grad = False или fc.bias.requires_grad = False

# Вот как устроена эта же функция в torch.nn.functional:
# она требует тензор, весы и не обязательное смещение при этом весы должны выполнять
# условие матричного умножения
# def linear(X, weight, bias=None):                 # смещение не обязательно
#     if X.dim() == 2 and bias is not None:         # если 2 оси и задано смещение
#         ret = torch.addmm(bias, X, weight.t())    # X@(w.t()) + b
#     else:
#         output = X.matmul(weight.t())
#         if bias is not None: output += bias
#         ret = output
#     return ret

#endregion

#region СЛОЙ ЭМБЕДДИНГА

# nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None,
# norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)

# Обязательными являются num_embeddings(размер массива) и embedding_dim(размерность)
# Принимает тензор с Long переменными

# создаст весы размерность (5,2)
emb = nn.Embedding(5, 2, padding_idx=0)
# X определяет индексы которые нужно выбрать из тензора весов
X = torch.tensor([0,2,1])
 
#print(emb.weight)   # tensor([ [s0 s0] [s1  s1] [s2  s2] [s3 s3] [s4 s4] ],
                    # requires_grad=True)
#print(emb(X))       # tensor([ [s0 s0] [s2  s2] [s1  s1] ],  grad_fn=<EmbeddingBackward0>)

# Параметры:

# paddind_idx - задает индексу постоянное значение нуля
# padding_idx=1 - значит в x[0][2] = [0 0] (т.к. emb.weight[0][2] = [0 0])
emb = nn.Embedding(5, 2, padding_idx=1)
#print(emb(X))       # tensor([ [s0 s0] [s2  s2] [0  0] ],  grad_fn=<EmbeddingBackward0>)
# Где это используется ? :
# Например в разговорных нейросетях:
# "Привет" => токены [2, 3]
# "Как дела" => токены [4, 5, 6] , то x выглядел бы так:
# [ [2 3 0] [4 5 6] ] - то есть там где 0 не будет происходить 
# вычислений, что очень удобно

# max_norm - задает максимальную длину вектора и если превышается, 
# то вектор перенормируется(меняет max_norm на ту длину которая превысила)
# По умолчанию это значение равно 2
# Формула для нахождения: N = math.sqrt(sum), где sum - сумма значений тензора
# Пример:
# emb(X) = [[ 0.5561, -0.1329],[ 0.3771, -0.0645],[ 0.3371, -0.3638]], то
# N[1] = math.sqrt(0.5561-0.1329) = 0.5718 и т.д.
emb = nn.Embedding(5, 2, max_norm=3)
#print(emb(X))   # tensor([ [s0 s0] [s1  s1] [s2  s2] [s3 s3] [s4 s4] ],
                # requires_grad=True)
# norm - выводит тензор с нормализованными значениями от 0 до 3(max_norm=3) для 
# каждого элемента по 1 оси emb(X)   
#print(torch.norm(emb(X),dim=1)) # [s s s], где s - значения нормализации
# Зачем нужна нормировка? :
# В тензоре могут быть 1000 значений скажем от 0 до 1 или от 1 до 1000
# Чтобы было удобнее с ними работать их нормируют в более комфортные значения
# Нормализация помогает привести данные к одинаковому масштабу

# scale_grad_by_freq - регулирует значения для индексов, то есть
# если true: часто встречающиеся индексы будут уменьшаться, а те что реже увеличиваться
# По итогу будет создан баланс между частыми и редкими индексами
weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6], [7, 8.1, 9]])
# from_pretrained - предварительно созданые векторы для быстрого использования:
# from_pretrained(embeddings, freeze=True, padding_idx=None, max_norm=None,
# norm_type=2.0, scale_grad_by_freq=False, sparse=False)
# freeze=False - для обновления весов и градиентов
emb = nn.Embedding.from_pretrained(weight, freeze=False, scale_grad_by_freq=False)
input = torch.LongTensor([0, 1, 1])   # Создать emb по первому индексу weight
output = emb(input)
loss = output.sum()
loss.backward()
# [1 1 1] - [0] индекс встречается 1 раз, [2 2 2] - [1] индекс встречается 2 раза,
# [0 0 0] - [2] индекс встречается 0 раз (тут стоят единицы, т.к. loss очень простая) 
#print(emb.weight.grad)          # [ [1 1 1] [2 2 2] [0 0 0] ]

#endregion

#region СЛОЙ КОНВОЛЮЦИИ

# nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, 
# dilation=1, groups=1, bias=True, padding_mode='zeros') - слой применяется 
# в основном применяется для картинок высотой rows, шириной cols и с in_channels 
# цветовых каналов(тем не менее может применяться не только для изображений)

# На вход входит тензор (N, in_channels, rows,cols)
# На выходе (N, out_channels, rows_out, cols_out)
# По выходному проход фильтры out_channels размерами 
# kernel_size(2,2 - размерность, если kernel_size=2)
# Глубина определяется in_channels

# Параметры:
# padding - задает то на сколько нужно расширить картинку перед прохождением фильтров
# padding_mode - задает то чем будет заполняться эта область
# (zeros, reflect, replicate,circular)
# duration - задает расстояние между пикселями попадающими в фильтр(шаг)

# Пример:
X = torch.zeros(1,1,3,4)    # [ [ [0 0 0 0] [0 0 0 0] [0 0 0 0] ] ]
X[0,0,:,:2] = 1             # [ [ [1 1 0 0] [1 1 0 0] [1 1 0 0] ] ] 
#print(X)   # (1,1,3,4) - одна выборка(1), один канал(1), размер изображения (3,4)

# т.к. kernel_size=2, то фильтры будут размерами (2,2)
# stride по умолчанию (1,1), то есть шаг равен 1 по ширине и высоте
# без смещения
conv = nn.Conv2d(1,1,kernel_size=2,bias=False)
#print(conv)     # Conv2d(1, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)

# Присваивание веса слою вручную(с no_grad, чтобы не считалось сразу, правило такое)
with torch.no_grad():
    conv.weight.copy_(torch.tensor([[-1.,1.], [-1.,1.]]))

# requires_grad=True т.к. это весы у них так всегда по умолчанию(если false, 
# то весы не обновляются, а значит модель не учиться)
#print( conv.weight )    # tensor([[-1.,1.], [-1.,1.]], requires_grad=True)
#print( conv.bias )      # смещение не объявляли
# Расчет выходного тензора(OUTnum - выходной, Hin - входной, K - размер фильтра):
# OUT1 = 1 - поскольку X по первой оси имеет 1, то есть за один прогон одно изображение
# OUT2 = 1 - поскольку у conv значение out_channels равно 1 - количество 
# фильтров(каналов) в слое
# Остальные по формуле: Hnum = (Hin-K[ind])/stride[0])+1
# Hin = (1,1,3,4); K = (2,2); stride = (1,1), то:
# OUT3 = ((Hin[2] - K[0])/1) +1 = ((3-2)/1) +1 = 2
# OUT4 = ((Hin[3] - K[1])/1) +1 = ((4-2)/1) +1 = 3
# Исходный тензор будет иметь размерность (1,1,2,3)
# [ [ [1 1 0 0] [1 1 0 0] [1 1 0 0] ] ]:
# 1 1 0 0
# 1 1 0 0
# 1 1 0 0
# [ [-1 1] [-1 1] ] :
# -1 1
# -1 1
# В таком случае считаем первое скалярное произведение:
# левое верхнее окно
# [ [-1 1] [-1 1] ] @ [ [1 1] [1 1] ] = 1*-1 + 1*1 + 1*-1 + 1*1 = -2+2 = 0 
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [1 0] [1 0] ] = -1*1 + 1*0 + -1*1 + 1*0 = -2
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [0 0] [0 0] ] = -1*0 + 1*0 + -1*0 + 1*0 = 0
# вниз и влево к краю
# [ [-1 1] [-1 1] ] @ [ [1 1] [1 1] ] = 1*-1 + 1*1 + 1*-1 + 1*1 = -2+2 = 0
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [1 0] [1 0] ] = -1*1 + 1*0 + -1*1 + 1*0 = -2
# правее на 1
# [ [-1 1] [-1 1] ] @ [ [0 0] [0 0] ] = -1*0 + 1*0 + -1*0 + 1*0 = 0
# Итого: [ [ [ [0 -2 0] [0 -2 0] ] ] ]
#print( conv(X) )    # tensor([[[[0 -2 0] [0 -2 0]]]], grad_fn=<ConvolutionBackward0>)

#endregion

#region СЛОЙ RNN

# nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='tanh', bias=True,
# batch_first=False, dropout=0, bidirectional=False)
# Предназначен для обработки последовательных данных(текст, временные ряды, 
# аудиофайлы и т.д.)
# Вычисляет новое скрытое состояние по старому и новому(входному)

# Параметры:
# input_size - размерность входа
# hidden_size - размерность выхода
# batch_first - задает индекс батча, что будет использоваться
# num_layers - задает размерность для первой оси скрытого слоя
# dropout - задает вероятность случайного забивания 0 в скрытых состояниях
# формы для того, чтобы избежать переобучения(при 1 вероятно не будеть учиться)
# biddirrectional - если true, то двунаправленная иначе однонаправленная:
# однонапрвленная - сеть генерирует данные по одному направлению к другому
# двунаправленна - сеть генерирует данные от одного к другому и к другому к одному
# (слева направо с права на лево). В таком случае скрытые состояния удваиваются, но
# и сеть становиться более мощной

# Размерность входа(seq_len, batch_size, input_size), 
# где seq_len - число RNN ячеек(входов)

# Слой возвращает все выходы формы(seq_len, batch_size, hidden_size)
# и последнее скрытое состояние формы(num_layers, batch_size, hidden_size)

X_dim  = 2           # размерность входов             = dim(x)
H_dim  = 4           # размерность скрытого состояния = dim(h)
L      = 3           # число входов (ячеек RNN слоя) - сколько векторов на вход
B      = 1           # число примеров (batch_size)

# Создание слоя 2 размерности входов и 4 размерностью скрытого состояния
# Если надо bidirectional=True, то применить к H0 на первой оси 2, а не 1 иначе ошибка
# поскольку при bidirectional=True существет уже два направления по скрытным слоям
rnn = nn.RNN(X_dim, H_dim)

# Входы для слоя:
X  = torch.zeros(L, B, X_dim)   # (3,1,2) [ [ [0 0] ] [ [0 0] ] [ [0 0] ] ]
H0 = torch.zeros(1, B, H_dim)   # (1,1,4) [ [ [0 0 0 0] ] ]

# На выходе: Y - выход; Hn - выход скрытого состояния
# X -> Y = (3,1,2) -> (3,1,4) (взяла 4 с HO, где (1,1,4)), т.к. на каждом 
# из 3 временных шагов(L) будет создано скрытое состояние размерности 4
# Hn = H0 = (1,1,4) = (1,1,4)
# Hn - просто запоминает последнее действие(размерность с которой работал)
Y, Hn = rnn(X, H0)                      # H0 не обязательно, по умолчанию и так 0

#print(tuple(Y.shape), tuple(Hn.shape))  #  (3, 1, 4) (1, 1, 4)
# Последнее значение Y и Hn совпадает, поскольку Hn = последнему присвоенному Y вектору
#print(Y)
#print(Hn)

#endregion

#region СЛОЙ LSTM

# torch.nn.LSTM(input_size, hidden_size, num_layers=1, nonlinearity='tanh', bias=True,
# batch_first=False, dropout=0, bidirectional=False)
# Абсолютный аналог RNN, который использует добавления памяти ячеек
# Ячейка памяти

X_dim  = 10          # размерность входов             = dim(x)
H_dim  = 20          # размерность скрытого состояния = dim(h)
L      = 3           # число входов (ячеек RNN слоя) - сколько векторов на вход
B      = 1           # число примеров (batch_size)

rnn = nn.LSTM(X_dim, H_dim, 2)

X  = torch.zeros(L, B, X_dim)
H0 = torch.zeros(1, B, H_dim)

output, (hn, cn) = rnn(input, (h0, c0))
print(output)
print((hn, cn))

#endregion

#region



#endregion